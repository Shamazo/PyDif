{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pydif-docs-milestone2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pF9XF7KUlo1U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Introduction\n",
        "\n",
        "\n",
        "PyDif is Python library for automatic differentiation, a computational technique for evaluating derivatives that has several distinct advantages compared to alternative computer-based methods for differentiation.\n",
        "\n",
        "\n",
        "Numerical methods, such as the finite differences method, are simple to implement but are plagued by floating point round-off errors and approximation errors, affecting accuracy and stability.\n",
        "\n",
        "On the other hand, symbolic differentiation can compute derivatives up to machine precision, but can quickly become very computationally expensive.\n",
        "\n",
        "As an alternative, automatic differentiation is capable of machine precision accuracy without the computational cost of symbolic differentiation.\n",
        "\n",
        "This has significant implications for an extremely wide variety of applications across science and engineering.\n",
        "\n",
        "In our case, we plan to offer a software library that can compute the gradient or Jacobian for any mathematical function a user has implemented in Python, supporting scalar-functions of scalar values, vector functions of vectors, and scalar functions of vectors.\n",
        "\n",
        "Users can leverage our software for their own applications, such as optimization, root-finding, and much more."
      ]
    },
    {
      "metadata": {
        "id": "aSv6Ho8spNZH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Installation\n",
        "\n",
        "PyDif is currently in development and not yet on PyPI. \n",
        "\n",
        "To use our software, clone or otherwise download our project repo from Github:\n",
        "https://github.com/pydif/cs207-FinalProject\n",
        "\n",
        "If you do not have numpy installed, run the following:\n",
        "\n",
        "```\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "Once numpy is installed, you can navigate to the cs207-FinalProject folder and start writing your software in that directory.\n",
        "\n",
        "Please refer to the \"How to Use Package\" section for guidance on how to correctly import the relvant modules and how to use them in your software.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cZUXyMu_q2-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Background\n",
        "\n",
        "####Chain Rule\n",
        "\n",
        "In calculus,  the derivative of the composition of two or more functions is defined as:\n",
        "\n",
        "$$\\dot{F}(x) = \\dot{g}(x)\\dot{f}(g(x))$$\n",
        "\n",
        "In automatic differentiation, this rule is frequently utilized. All functions, even seemingly simple ones, use this rule. For example, $F(x) = sin(x)$ can be rewritten in the form $f(g(x))$ where $g(x)$ is simply $x$ and $f(x)$ is $sin(x)$. Thus, we have:\n",
        "\n",
        "\n",
        "$$\\dot{F}(x) = \\dot{g}(x)\\dot{f}(g(x))$$\n",
        "$$\\dot{F}(x)  = 1 *cos(x)$$\n",
        "\n",
        "where 1 is $\\dot{g}(x) = 1$ and $\\dot{f}(x) = cos(x)$.\n",
        "\n",
        "For a more complicated example, let us take $F(x) = sin(x^{2})$\n",
        "\n",
        "$$ f(x) = sin(g(x))$$\n",
        "$$ g(x) = x^{2}$$\n",
        "$$ \\dot{f}(x) = cos(g(x))$$\n",
        "$$ \\dot{g}(x) = 2x$$\n",
        "$$\\dot{F}(x) = \\dot{g}(x)\\dot{f}(g(x))$$\n",
        "$$\\dot{F}(x) = 2xcos(x^{2})$$\n",
        "\n",
        "Using this rule, one can calculate the derivatives of increasinly complex functions, all while only needing to calculate the derivatives of a series of elementary functions.\n",
        "\n",
        "####Computational Graph\n",
        "\n",
        "The computation graph describes the order of calculations done to compute the derivative. For example consider the funcion $f\\left(x, y, z\\right) = \\dfrac{1}{xyz} + \\sin\\left(\\dfrac{1}{x} + \\dfrac{1}{y} + \\dfrac{1}{z}\\right)$ where we want to evaluate the partial derivatives at (1, 2, 3). The table representation of the graph would look like this. Each row of the table represents one elementary step in the calculation. The function in each row is an elementary function on a combination of earlier rows, which lets us step by step build up the derivative by repeatedly applying the chain rule and at the same time we can also evaluate the function. The table can also be presented in a graph format, but this quickly becomes unwiedly for complicated functions. \n",
        "\n",
        "\n",
        "| Trace | Elementary Function | Current Value | Elementary Function Derivative | $\\nabla_{x}$ Value  | $\\nabla_{y}$ Value  | $\\nabla_{z}$ Value  |\n",
        "| :-------: | :-----------------: | :-----------: | :----------------------------: | :-----------------: | :-----------------: | :-----------------: |\n",
        "| $x_{1} = x$ | $x_{1}$ | 1 | $\\dot{x}_{1}$ | $1$ | $0$ | $0$ | \n",
        "| $x_{2} = y$ | $x_{2}$ | 2 | $\\dot{x}_{2}$ | $0$ | $1$ | $0$ | \n",
        "| $x_{3} = z$ | $x_{3}$ | 3 | $\\dot{x}_{3}$ | $0$ | $0$ | $1$ | \n",
        "| $x_{4}$ | $1/x_{1}$ | 1 | $-\\dot{x}_{1}/x_{1}^{2}$ | $-1$ | $0$ | $0$ | \n",
        "| $x_{5}$ | $1/x_{2}$ | 1/2 | $-\\dot{x}_{2}/x_{2}^{2}$ | $0$ | $-1/4$ | $0$ | \n",
        "| $x_{6}$ | $1/x_{3}$ | 1/3 | $-\\dot{x}_{3}/x_{3}^{2}$ | $0$ | $0$ | $-1/9$ | \n",
        "| $x_{7}$ | $x_{4} * x_{5}$ | 1/2 | $\\dot{x_4}x_5 + x_4 \\dot{x_5}$ | $-1/2$ | $-1/4$ | $0$ | \n",
        "| $x_{8}$ | $x_{7} * x_{6}$ | 1/6 | $\\dot{x_7}x_6 + x_7 \\dot{x_6}$ | $-1/6$ | $-1/12$ | $-1/18$ | \n",
        "| $x_{9}$ | $x_{4} + x_{5} + x_{6}$ | 11/6 | $\\dot{x_4} + \\dot{x_5} + \\dot{x_6}$ | $-1$ | $-1/4$ | $-1/9$ | \n",
        "| $x_{10}$ | $Sin(x_9)$ | 0.9657 | $\\dot{x_9}Cos(x_9)$ | $0.2595$ | $-0.06488$ | $-0.02883$ | \n",
        "| $x_{11}$ | $x_{10} + x_{8} $ | 1.1324 | $\\dot{x_{10}} + \\dot{x_8}$ | $0.0928$ | $-0.0184$ | $-0.0267$ | \n",
        "\n",
        "\n",
        "\n",
        "#### Dual Numbers\n",
        "\n",
        "Much like how imaginary numbers of the form $x+yi$ are an extension of the real plane that have some very useful properties, dual numbers are another interesting type of numbers of the from $x+y\\epsilon$.\n",
        "\n",
        "Similar to how we defined $i$ to have the property that $i^2 = -1$, the $\\epsilon$ in dual numbers is defined such that $\\epsilon^2 = 0$ (note: $\\epsilon$ here is not 0!). A neat property of dual numbers can be illustrated with a very simple example.\n",
        "\n",
        "Consider $(x+yi)^2$:\n",
        "$$ (x+yi)^2 = x^2 + 2xyi + y^2i^2 = x^2 + 2xyi + y^2 $$\n",
        "In particular, notice how the magnitude of the imaginary component ($y$) \"feeds into\" the real value of the result (the +y^2 contribution).\n",
        "\n",
        "Now instead, consider $(x+y\\epsilon)^2$:\n",
        "\n",
        "$$ (x+y\\epsilon)^2 = x^2  + 2xy\\epsilon + y^2\\epsilon^2 = x^2 + 2xy\\epsilon (\\text{recall:} \\epsilon^2 = 0!) $$\n",
        "Notice how with dual numbers, the magnitude of the dual component ($y$) _does not_ feed into the real value of the result.\n",
        "\n",
        "Amongst other things, this quirk of the dual number makes it particularly suited for automatic differentiation. Consider the following:\n",
        "\n",
        "Evaluate $y = x^2$ when $x\\leftarrow x + \\epsilon x^{\\prime}$.\n",
        "\n",
        "$y = (x + \\epsilon x^{\\prime})^2$\n",
        "\n",
        "$y = (x^2 + 2 x x^{\\prime} \\epsilon + x^{\\prime^2} \\epsilon ^2)$\n",
        "\n",
        "$y = (x^2 + 2 x x^{\\prime} \\epsilon)$\n",
        "\n",
        "Notice here that by evaluating $y = x^2$ at $x\\leftarrow x + \\epsilon x^{\\prime}$, we have calculated its derivative ($2x$)! Neat! \n",
        "\n",
        "In our implementation of automatic differentiation, dual numbers will be used to keep track of a function's value and it's derivative simulatenously.\n",
        "\n",
        "\n",
        "#### Elementary Functions\n",
        "\n",
        "In order to evaluate derivatives of a variety of different functions iteratively through the chain rule, we ultimately need to rely on a minimum set of so-called \"elementary functions.\" These elementary functions consist of arithmetic operations (+, -, x, /) as well as atomic-sized, differentiable functions of a single variable that can be used as building blocks for more complex functions.\n",
        "\n",
        "\n",
        "\n",
        "Here is a list of elementary functions:\n",
        "\n",
        "* Addition, subtraction, multiplication, division\n",
        "* Absolute Value\n",
        "* Powers\n",
        "* Roots\n",
        "* Exponential\n",
        "* Log\n",
        "* Trigonometric Functions\n",
        "* Inverse Trigonometric Functions\n",
        "\n",
        "\n",
        "\n",
        "Explicitly defining the evaluation of these functions and their derivatives makes it possible to use the chain rule to evaluate the derivative of any differentiable function that is a combination of multiple elementary functions.\n",
        "\n",
        "#### Seed Vectors\n",
        "\n",
        "\n",
        "The use of seed vectors becomes apparent when considering more complicated examples. Consider a vector function $\\textbf{f}(\\textbf{x})$ that takes a vector input $\\textbf{x} = (x_1, x_2)$:\n",
        "\n",
        "$$\\textbf{f(x)} = \\begin{bmatrix} 2x_1+2x_2 \\\\ x_1x_2\\end{bmatrix} $$\n",
        "\n",
        "Let $\\textbf{x}_{o} = (x_{o_1}, x_{o_2})$ be the outputs from the function. And define a directional derivative $D_{p}$ and seed vector $\\textbf{p}$ such as follows:\n",
        "\n",
        "$$D_{p}x_{o_i} = \\sum_{j=1}^{2}{\\dfrac{\\partial x_{o_i}}{\\partial x_{j}}p_{j}}$$\n",
        "\n",
        "Computing the directional derivative for $\\textbf{f}(\\textbf{x})$:\n",
        "\n",
        "$D_{p}x_{o_1} = {\\dfrac{\\partial x_{o_1}}{\\partial x_{1}}p_{1}} + {\\dfrac{\\partial x_{o_1}}{\\partial x_{2}}p_{2}}  = 2p_{1} + 2p_2$\n",
        "\n",
        "$D_{p}x_{o_2} = {\\dfrac{\\partial x_{o_2}}{\\partial x_{1}}p_{1}} + {\\dfrac{\\partial x_{o_2}}{\\partial x_{2}}p_{2}} = x_2p_1 + x_1p_2$\n",
        "\n",
        "This can be written more compactly as the Jacobian: $\\textbf{J}=$\n",
        "$\n",
        "  \\begin{bmatrix}\n",
        "        2p_{1}   & 2p_2                        \\\\\n",
        "        x_2p_1 & x_1p_2\n",
        "      \\end{bmatrix}\n",
        " $\n",
        " \n",
        "Notice that by choosing different values for the seed vector $\\textbf{p}$ allows us to select different components of the Jacobian! We can recover ${\\dfrac{\\partial x_{o}}{\\partial x_{1}}}$ by choosing $\\textbf{p} = (p_1, p_2) = (1,0)$, and recover ${\\dfrac{\\partial x_{o}}{\\partial x_{2}}}$ by choosing $\\textbf{p} = (0,1)$. We can also recover the full Jacobian by choosing $\\textbf{p} = (1/\\sqrt{2},1/\\sqrt{2})$.\n",
        "\n",
        "Typically, we would only be interested in the action of the Jacobian on some vector. The use of this seed vector allows us to compute the components of the Jacobian that we are interested in! We can however always still recover the full Jacobian by choosing an appropriate seed vector."
      ]
    },
    {
      "metadata": {
        "id": "n8r2_hZcodUv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Software Organization\n",
        "The directory structure of pydif\n",
        "\n",
        "  ```\n",
        "     pydif\\\n",
        "           pydif\\\n",
        "                 __init__.py\n",
        "                 pydif.py\n",
        "                 test_pydif.py\n",
        "                  dual/\n",
        "                       __init__.py\n",
        "                      dual.py\n",
        "                      test_dual.py\n",
        "                  elementary/\n",
        "                       __init__.py\n",
        "                      elementary.py\n",
        "                      test_elementary.py\n",
        "                   \n",
        "           README.md\n",
        "           setup.py\n",
        "           LICENSE.txt\n",
        "           requirements.txt\n",
        "  ```\n",
        "  \n",
        "Each of our modules has a corresponding test file, and testing will be performed through pytest. We will use TravisCI for continuous integration and Coveralls for assessing coverage. pydif.py will contain the core of our package and is where we will actually implement automatic differentiation. dual.py will contain our implementation of dual numbers, and elementary.py will contain the elementary functions. The project will be licensed under the MIT License.  "
      ]
    },
    {
      "metadata": {
        "id": "B6jHJCwqoC0e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How to use package"
      ]
    },
    {
      "metadata": {
        "id": "xyiVgnScoGRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "An example usage of the package is provided as newton-example.py in the project repository. Following that provided example, \n",
        "\n",
        "The mantra to import the autodiff object and the relevant elementary functions:\n",
        "\n",
        "```\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(os.getcwd(),'pydif'))\n",
        "from pydif.pydif import autodiff #import autodiff objects\n",
        "from pydif.elementary import elementary as el #imports the elementary functions\n",
        "```\n",
        "We first define the function that we wish to evaluate:\n",
        "\n",
        "```\n",
        "def f(x):\n",
        "        return x - el.exp(-2.0 * el.sin(4.0*x) * el.sin(4.0*x))\n",
        "```\n",
        "Then instead of having to manually define the jacobian, we can instead define a autodiff object that automatically evaluates the derivative.\n",
        "```\n",
        "dfdx = autodiff(f)\n",
        "```\n",
        "\n",
        "The derivative of the function at any point can then be retrieved as simply as follows!\n",
        "\n",
        "```\n",
        "gradient = dfdx.get_der(point, jacobian=True)[0]\n",
        "```\n",
        "\n",
        "The evaluation of gradient from the autodiff object at a `point` using `jacobian=True` returns a list of the partial derivatives. Since this function only has one input parameter `x`, we simply take the first element from this list each time."
      ]
    },
    {
      "metadata": {
        "id": "bzBLuVcKoeX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dyzU3wrPogFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Elementary functions\n",
        "In order to implement automatic differentiation functions must be wrapped with library specific code. This means, for example, that you cannot use sin or np.sin in your code, rather you need to use the pydif implemention of sin. Pydif currently supports the following elementary functions which correspond to numpy functions of the same name. More elementary functions will be implemented in future releases. \n",
        "\n",
        "\n",
        "\n",
        "*   cos(x)\n",
        "*   sin(x)\n",
        "*   tan(x)\n",
        "* exp2(x)\n",
        "* log(x)\n",
        "* log2(x)\n",
        "* log10(x)\n",
        "\n",
        "These functions are used like so:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from pydiff.elementary import elementary as el \n",
        "\n",
        "def example_func(x):\n",
        "      return 5 * el.cos(x) + el.log10(x)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EFXsJYiUBS3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dual Numbers\n",
        "\n",
        "Pydif uses Dual numbers to quickly calculate derivatives of complicated functions. In order to instantiate an object of the class Dual,  one must pass in two arguments: the value of a function at a point and an array or array-like object of partial derivatives at a point. Pydif duals currently support the following elementary operations:\n",
        "\n",
        "*  addition\n",
        "*  subtraction\n",
        "* multiplication\n",
        "* division\n",
        "* exponentiation\n",
        "* negation\n",
        "\n",
        "These functions are used like so:\n",
        "\n",
        "```\n",
        "import pydif.dual as Dual \n",
        "\n",
        "a = Dual(1, 2)\n",
        "\n",
        "print(a)\n",
        ">>> [1,2]\n",
        "\n",
        "b = Dual(1, [3,4,5])\n",
        "\n",
        "print(b)\n",
        ">>> [1, [3,4,5]]\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "diFM8-L9_ba-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## AutoDiff\n",
        "\n",
        "To actually evaluate the value and derivates of functions, autodiff objects have to be defined. These autodiff objects are initialized with a function of interest. Values and derivates are then evaluated at specific points by calling functions of the autodiff object.\n",
        "\n",
        "autodiff objects expose the following functions to the users for function evaluation:\n",
        "\n",
        "* get_val(pos)\n",
        "\n",
        "This evaluates the function of interest at the specified position.\n",
        "\n",
        "* get_der(pos, jacobian=False, dir=None):\n",
        "\n",
        "This evaluates the derivate of the function at the specified position. The derivative can be evaluated in several modes:\n",
        "Assume the function being evaluated is $u(a)$, $u(x,y)$.\n",
        "\n",
        "1. Vanilla: $\\frac{d}{d a}u(a)$ (just takes the derivative of the function)\n",
        "2. Jacobian: $\\frac{\\partial}{\\partial x}u(x,y)$, $\\frac{\\partial}{\\partial y}u(x,y)$ (returns the partial derivates of the function)\n",
        "3. Directional derivates (not implemented yet, would return the derivates along a specified direction vector)\n",
        "\n",
        "These functions are used like so:\n",
        "\n",
        "```\n",
        "\n",
        "import pydif\n",
        "from elementary import elementary as ele\n",
        "\n",
        "\n",
        "def func(x,y,z):\n",
        "    return 1/(x + y + z)\n",
        "    \n",
        "    \n",
        "ad = pydif.autodiff(func)\n",
        "\n",
        "\n",
        "pos = [0,1,13] #evaluate at the position (x,y,z) = (0,1,13)\n",
        "\n",
        "\n",
        "ad.get_val(pos) #returns the value of the function evaluated at the position\n",
        "\n",
        "\n",
        "ad.get_der(pos) #returns the derivative of the function evaluated at the position\n",
        "\n",
        "ad.get_der(pos, jacobian=True) #returns the partial derivates of the function evaluated at the position\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "rVXqGgAaoumN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mSlhl2UkQ3ki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementation Details\n",
        "## General notes\n",
        "This library only depends on NumPy. It is tested with version 1.15.4.\n",
        "\n",
        "## Duals\n",
        "\n",
        "The Dual class is used by pydif to quickly take the derivative by storing the value of a function at a point, as well as the partial derivatives at that point. \n",
        "\n",
        "The first argument is the value of the function and the second is a numpy array of partial derivatives. Numpy is used to allow for componentwise operations across partial derivatives.\n",
        "\n",
        "The class itself consists of two attributes: val and der, identical to the above arguments. Dual.val is a float that contains the value of the function at a point. Dual.der on the hand contains a numpy array of partial derivatives at a point.l\n",
        "\n",
        "The elementary operators for addition, subtraction, multiplication, division, power and negation were all overloaded, as well as the reverse operators. For the derivatives, operators were overlaoded to adhere to properties of differentiation, such as the product rule for mulitplication. \n",
        "\n",
        "Each operator first tries to operate assuming the other input is a dual number and falls back to scalar operations if necessary. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Elementary functions\n",
        "\n",
        "Elementary functions are small wrappers around their numpy equivilants to support operations on Dual numbers. Each function is a try except clause which first trys the input as a dual number and falls back to treating it as a normal python numeric type. \n"
      ]
    },
    {
      "metadata": {
        "id": "M23M_g0YRI9W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## AutoDiff\n",
        "\n",
        "The autodiff class in pydif.py implements the necessary logic to actually use these dual numbers to evaluate the value and derivatives of functions at specified position.\n",
        "\n",
        "Autodiff objects can be initialized by providing a function of single variables of the form f(x,y,z,...). The autodiff objects can then be evaluated at specified positions to find the value of the function, and its derivatives. Autodiff objects implement the necessary logic to initialize and evaluate the necessary dual numbers. When autodiff objects are initialized, the function and the number of parameters that the function takes as input are stored as attributes of the autodiff object.\n",
        "\n",
        "Autodiff objects have two main functions that will be called get_val() and get_der() to evaluate the value and derivates of the function respectively. \n",
        "\n",
        "When either of these functions are called, autodiff objects first check the requested position to evaluate the function at to ensure that the shape matches the function call signature, a value error is thrown otherwise. This logic is handeled internally by autodiff objects by passing the requested position to evaluate the function at to an internal function (_check_pos()) which does the required shape comparison. \n",
        "\n",
        "Then, the autodiff object calls the _eval() internal function with the necessary parameters to actually evaluate the function at this position. Notice that regardless of whether get_val() or get_der() are called, both the value and derivative are calculated each time. Within the _eval() internal function, autodiff objects initialize the appropriate number of dual numbers in the appropriate fashion (e.g. with single valued derivative attribute if not requesting jacobian, or a numpy array for the derivative attribute if requiring the jacobian (to keep track of all the partial derivatives)). Autodiff objects then call the function using these initialized dual numbers are input and collected the output from these functions, which are also dual numbers! The details of dual number operations have already been described above when talking about the Dual class. Either the real attributes of the dual numbers (Dual.val) or the derivative attributes of the dual numbers (Dual.der) are returned depending on which of the evaluation routines was called and with what parameters.\n",
        "\n",
        "For the jacobian, returned as a list of partial derivatives with the order the same as the function call signature. For example, consider a function of the form f(x,y), then the call to get_der() with jacobian=True will return a list of two partial derivatives, with respect to x and y respectively (same order as function call definition).\n",
        "\n",
        "In the near future, the autodiff class will also implement the evaluation of derivates in a particular direction."
      ]
    },
    {
      "metadata": {
        "id": "Mnu5ZSl_nnZk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Future\n",
        "In future releases of this library we hope to implement the backwards mode of automatic differentiation. Consider a function $f: R^n \\rightarrow R^m$\n",
        "\n",
        "Backwards mode is more efficient at computing gradients of functions with $n > > m $. Forward mode scales O(n) with the number of input variables if we want to find all the partial derivatives, since we need to run the computation with n different seed vectors.  Backwards mode starts from the end of our compuational graph and works backgrounds and runs in O(m) time. Many applications have functions of many to a few variables, most notably neural networks which can be expressed as functions with thousands of input variables but only a few output variables."
      ]
    },
    {
      "metadata": {
        "id": "bHoAUSByUpQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}